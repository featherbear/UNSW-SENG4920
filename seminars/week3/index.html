<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Seminar: Week 3 - SENG4920 Musings</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="z5206677"><meta name=description content="Scenarios Accepting a contract for part of a project where you believe the project will fail."><meta name=keywords content="featherbear,SENG4920,UNSW"><meta name=generator content="Hugo 0.68.3 with theme even"><link rel=canonical href=../../seminars/week3/><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../manifest.json><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><link href=../../sass/main.min.651e6917abb0239242daa570c2bec9867267bbcd83646da5a850afe573347b44.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><link rel=stylesheet href=../../css/typedjs.shortcode.css><link rel=stylesheet href=../../css/fixDetails.css><meta property="og:title" content="Seminar: Week 3"><meta property="og:description" content="Scenarios Accepting a contract for part of a project where you believe the project will fail."><meta property="og:type" content="article"><meta property="og:url" content="/seminars/week3/"><meta property="article:published_time" content="2020-09-30T12:21:26+10:00"><meta property="article:modified_time" content="2020-11-03T14:18:04+11:00"><meta itemprop=name content="Seminar: Week 3"><meta itemprop=description content="Scenarios Accepting a contract for part of a project where you believe the project will fail."><meta itemprop=datePublished content="2020-09-30T12:21:26+10:00"><meta itemprop=dateModified content="2020-11-03T14:18:04+11:00"><meta itemprop=wordCount content="2030"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Seminar: Week 3"><meta name=twitter:description content="Scenarios Accepting a contract for part of a project where you believe the project will fail."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=../../ class=logo>SENG4920 Musings</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=../../><li class=mobile-menu-item>Home</li></a><a href=https://github.com/featherbear/UNSW-SENG4920><li class=mobile-menu-item>GitHub</li></a><a href=../../categories/><li class=mobile-menu-item>Categories</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=../../ class=logo>SENG4920 Musings</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=../../>Home</a></li><li class=menu-item><a class=menu-item-link href=https://github.com/featherbear/UNSW-SENG4920>GitHub</a></li><li class=menu-item><a class=menu-item-link href=../../categories/>Categories</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Seminar: Week 3</h1><div class=post-meta><span class=post-time>2020-09-30</span><div class=post-category><a href=../../categories/seminars/>Seminars</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#scenarios>Scenarios</a></li><li><a href=#essay-discussion>Essay Discussion</a><ul><li><a href=#ethical-robots-in-warfare>Ethical Robots in Warfare</a></li><li><a href=#drones-robots-and-the-ethics-of-war>Drones, Robots and the Ethics of War</a></li><li><a href=#grounding-drones-ethical-use-reasoning>Grounding Drones' Ethical Use Reasoning</a></li></ul></li></ul></nav></div></div><div class=post-content><h1 id=scenarios>Scenarios</h1><p><strong>Accepting a contract for part of a project where you believe the project will fail.</strong> You are a small company with special expertise offered a contract to deliver a small software component of the new robotic army to be developed by the US military. You believe you can deliver on your contract, however, your component forms only a part of a larger system that you believe is unlikely to meet its objectives (variant: you also have moral objections to the idea of robot warfare).</p><blockquote><p>What are the ethical issues involved, if any?</p></blockquote><p>Conflict of interest with your duty. You believe against robot based warfare but you still take on the project, this is going against duty based ethics. This is clearly going against Kant thinking. The project is not going to be successful anyway, and you are delivering on your part so this is ok in consequential thinking.</p><blockquote><p>What behaviour of whom is unethical or not unethical?</p></blockquote><p>The company taking the contract.</p><p><strong>Kant</strong></p><p>The act of taking on the project is not ethical as the author has a moral disagreement with the work he is going to take on</p><p>(The act of taking is ethical under duty based model as you can deliver on the contract with your special expertise and help US military)</p><p><strong>Mill</strong></p><p>The act of taking on the project is more ethical than unethical as he will be producing a product, but he know that the product will fail and not produce any consequences (in the form of taking human lives).</p><p>This can be flipped if the act of the robot failing will result in more human deaths than what it should.</p><blockquote><p>Formulate ethical arguments in favour and against each described course of action.</p></blockquote><p>Take contract: (See above)<br>Deny contract: Kant</p><blockquote><p>Develop arguments for alternative courses of action that are more ethically justifiable.</p></blockquote><ul><li>Only 2 courses of action, and not enough information.</li><li>Changing the contract.</li><li>Raise issue project is going to fail.</li></ul><hr><p><strong>Developer relying on questionable inputs to test software.</strong> You are a software developer working on one module of a larger system. Your module requires input from other modules of the system. You receive an article from an eminent software specialist convincing you that the inputs from the other modules cannot be trusted. Therefore neither your software, nor the system as a whole, can accomplish its task. You show this article to your supervisor, who says that this is not a problem, that your responsibility is to ensure that your part of the system functions correctly.</p><p><em>”<code>Questionable</code>” - not completely honest, reasonable, or acceptable - Collins Dictionary</em></p><blockquote><p>What are the ethical issues involved, if any?</p></blockquote><ul><li>Lack of software quality assurance</li><li>"Commitment to Excellence"</li><li>"Fairness"</li></ul><p><img src=https://josephsononbusinessethics.com/2010/12/12-ethical-principles-for-business-executives/ alt=Links></p><blockquote><p>What behaviour of whom is unethical or not unethical?</p></blockquote><p>Software developer: Ethically responsible enough to show to supervisor, asking for clarification first. Not enough context given to show what they did afterwards, so nothing unethical has been committed.</p><p>Software specialist: Ethical (Concern for others)</p><p>Supervisor: Unethical (Ignoring concern, forcing responsibility)</p><blockquote><p>Formulate ethical arguments in favour and against each described course of action.</p></blockquote><ul><li>Software specialist telling the software developer<ul><li>For: Aware of the implications (working with bad input) that the developer will invariably have to do - so wants to raise it beforehand</li><li>Against: Planting doubt, unnecessary strife</li></ul></li><li>Software developer alerting the supervisor<ul><li>For: “Commitment to Excellence” - Brought attention to a concern with their work that may affect the quality of the final software solution</li><li>Against: - asking is never wrong -</li></ul></li><li>Supervisor responding to the developer<ul><li>For: <s>lol, his job</s></li><li>Against: Should investigate further</li></ul></li></ul><blockquote><p>Develop arguments for alternative courses of action that are more ethically justifiable.</p></blockquote><p>Correctly specifying the inputs from other modules (and fixing these modules to be trustworthy) would allow the entire system to be tested correctly.</p><p>The supervisor should honour his duty (Kantian) to oversee a successful implementation of the whole system (rather than just individual parts). Reframing this under Millian ethics, the consequences of incompatible modules is non-functional software and so the same applies.</p><hr><p><strong>Accessing commercial computer services.</strong> Without malicious intent, you write a program that attempts to connect to various web sites without the need to provide any authentication. After connecting to one such site, you receive a welcome message to an expensive financial service, and offered free of charge a sample use of the service by providing a name and e-mail address. You do this by providing someone else's name and a fake e-mail address. By examining the web service, you work out how to access services that the bank normally charges for, however you do not use these services. Bank officials report your activities to the Australian Federal Police and claim that you have used their service without authorization.</p><blockquote><p>What are the ethical issues involved, if any?</p></blockquote><ul><li>Identity Fraud</li><li>Obtaining free of charge Bank Services</li><li>False accusation</li></ul><blockquote><p>What behaviour of whom is unethical or not unethical?</p></blockquote><ul><li>The person making the program, because he provided a fake name and email and (even if unintentionally) found a way to access paid services of the bank</li><li>The Bank, because they claim you used the services, but you did not</li></ul><blockquote><p>Now formulate ethical arguments in favour and against each described course of action</p></blockquote><p>Against:</p><ul><li>Breaking terms of service of the commercial services</li><li>Identity fraud through fake email and name</li><li>Should have consent of the counterparty</li><li>In terms of Kantian Ethics, since he did find a way to access the service, it is an ethically incorrect action</li></ul><p>For:</p><ul><li>Doesn’t use the paid services, even though he had access</li><li>In terms of consequentialism, since he doesn’t use the service then there are no negative consequences and therefore not ethically incorrect.</li></ul><blockquote><p>Alternative courses of action</p></blockquote><ul><li>Obtain consent from the Financial Service to try to find backways into the paid services</li><li>Notifying the Bank, that you were able to get in, before they find out</li><li>Consider any of the sample essays, and answer the following questions:</li></ul><hr><p><strong>Building on existing software.</strong> You work in a small software company looking for new product ideas. You purchase and study a commercially available software package, and conclude that you can build a far superior system that essentially performs the same function, targeting users of the existing software as customers. To make it easier for users to transition to your product, you use a similar interface to the existing system, however your software is independently produced. You advertise your software as being compatible with the existing product. Your new product is successful, but the company producing the existing system threatens legal action for copyright infringement.</p><blockquote><p>What are the ethical issues involved, if any?</p></blockquote><ul><li>Making a similar product is not necessarily illegal</li><li>Bringing false legal action against a competitor</li><li>Copying the design of another available software for your own software</li></ul><blockquote><p>What behaviour of whom is unethical or not unethical?<br>Also formulate ethical arguments in favour and against each described course of action.</p></blockquote><p><strong>Existing Company</strong></p><ul><li>Threatening legal action for wrong reasons potentially, they may may just want to remove competition from the market. (Unethical)</li><li>Kantian ethics, the existing company are violating perfect duty by preventing others from developing competing software.</li><li>(c) By consequentialism, they are deferring the ethical decision to third party, which they believe will make the correct decision.</li><li>Protect their copyright (Ethical).</li><li>(c) By the Kantian ethics, we have a duty not to lie, steal etc. The existing company sees this new software as an instance of stealing, so it is their duty to stop it.</li></ul><p><strong>New Company</strong></p><ul><li>Copying the design of commercially available software for their own purposes (Unethical).</li><li>May be trying to create competition in the market for what they see as an improved solution (Ethical).</li><li>(c) By consequentialism: the new company believes that the software they are making will have a good outcome by improving the existing software, so the premise of stealing code does not matter.</li><li>(c) By Kantian ethics, the new company are violating perfect duty by copying a design, which cannot be applied to the general case for all other software.</li></ul><blockquote><p>Develop arguments for alternative courses of action that are more ethically justifiable.</p></blockquote><ul><li>Both companies collaborating and creating better software together</li><li>The new company should have viewed the license before they began developing their software, and seen if they could come to an agreement with the old company.</li></ul><hr><p><strong>Diverting project funds.</strong> You are a project manager responsible for two projects that share some software. One project is falling behind schedule, while another is ahead of schedule. Without informing your superior, you allow a developer working on the second project to devote some time to the first project, but charge the work to the second project. As a result, both projects are completed on time and on budget.</p><blockquote><p>What are the ethical issues involved, if any?</p></blockquote><ul><li>Diverting resources from one project to another, thus using one party’s funds for the gains of another</li><li>Not being transparent with resource usage</li></ul><blockquote><p>What behaviour of whom is unethical or not unethical?</p></blockquote><ul><li>The project manager, and the developer</li></ul><blockquote><p>Alternatives</p></blockquote><ul><li>Inform superior and bill the customers properly<ul><li>Kant - Ethical, as you have a duty to inform your superior of all problems</li><li>Mill - Ethical since both projects succeed</li></ul></li><li>Do exactly what was done in the scenario<ul><li>Kant - Unethical, as you have a duty to not lie to your superior/company/customer</li><li>Mill - Ethical, From the companies pov this is good. Both projects succeeded.</li></ul></li><li>Do nothing (stick to the project fund plan)<ul><li>Kant - Unethical, your inaction makes you a bystander</li><li>Mill - Unethical one project fails while the other is overcharged</li></ul></li></ul><hr><h1 id=essay-discussion>Essay Discussion</h1><h2 id=ethical-robots-in-warfare>Ethical Robots in Warfare</h2><p>Resource: <a href=./Arkin.pdf>Ethical Robots in Warfare</a></p><blockquote><p>Can you clearly state one or more of the author's conclusions?</p></blockquote><ul><li>We should continue to research robotic warfare</li></ul><blockquote><p>What argument (if any) is made in support of those conclusions?</p></blockquote><ul><li>Ethical robots can outperform humans as soldiers</li><li>Ethical robots can better adhere to laws of war</li><li>Research into robotics will inevitably be used in warfare, even if not researched for that reason. Thus, it is better to tackle the issue of robots in warfare directly, rather than avoid it.</li></ul><blockquote><p>What ethical reasoning approach (if any) is used to make this argument?</p></blockquote><ul><li>Duty (These robots can be more ethical so you have a duty to work toward it)</li><li>Consequentialism (inevitability => the outcome will be the same regardless)</li></ul><blockquote><p>Is there any evidence given in support of claims used in the argument?</p></blockquote><ul><li>“Fear and hysteria are always latent in combat, often real, and they press us toward fearful measures and criminal behavior”</li><li>Avoidance of the human psychological problem of “scenario fulfillment” is possible</li><li>“Military systems (including weapons) now on the horizon will be too fast, too small, too numerous, and will create an environment too complex for humans to direct”</li></ul><blockquote><p>Is this evidence convincing, or is there other evidence against the claim?</p></blockquote><ul><li>The essay lists some opposing arguments</li></ul><blockquote><p>Is the argument coherent (strong connections from claims to conclusion)?</p></blockquote><p>Yes. But there isn’t much depth</p><h2 id=drones-robots-and-the-ethics-of-war>Drones, Robots and the Ethics of War</h2><p>Resource: <a href=./Statman.pdf>Drones, Robots and the Ethics of War</a></p><blockquote><p>Can you clearly state one or more of the author's conclusions?</p></blockquote><ul><li>Pro Drones, because they are no less ethical than current tools of war</li><li>Drones are no less ethical than existing tools of war (missile cruisers, tanks, guns)</li></ul><blockquote><p>What argument (if any) is made in support of those conclusions?</p></blockquote><ul><li>If you use a Tank and a Drone, a Tank will actually have more negative consequences because it is less effective and Tanks are more prone to have collateral damage</li></ul><blockquote><p>What ethical reasoning approach (if any) is used to make this argument?</p></blockquote><ul><li>A drone does not provide any change the ethical state of war - A tool is a tool, weapon is a weapon</li><li>Soldiers don’t need to be deployed (Reduce risk of harm)</li></ul><blockquote><p>Is there any evidence given in support of claims used in the argument?</p></blockquote><ul><li>It has happened in the past, Crossbow -> Machine Gun, Foot Soldier -> Tanks & Planes</li></ul><blockquote><p>Is this evidence convincing, or is there other evidence against the claim?</p></blockquote><ul><li>Not really, as Killing Drones are not abundantly used in war</li></ul><blockquote><p>Is the argument coherent (strong connections from claims to conclusion)?</p></blockquote><h2 id=grounding-drones-ethical-use-reasoning>Grounding Drones' Ethical Use Reasoning</h2><p>Resource: <a href=./Kinne-Stojanov.pdf>Grounding Drones' Ethical Use Reasoning</a></p><p>...</p></div><footer class=post-footer><nav class=post-nav><a class=next href=../../seminars/week2/><span class="next-text nav-default">Seminar: Week 2</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-left"></i></a><a class=prev href=../../seminars/week4-uber-autonomous-car-crash/><i class="iconfont icon-right"></i><span class="prev-text nav-default">Seminar: Week 4 - Software Disasters: Uber Autonomous Car Crash</span>
<span class="prev-text nav-mobile">Prev</span></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:z5206677@student.unsw.edu.au class="iconfont icon-email" title=email></a><a href=https://www.linkedin.com/in/andrewjinmengwong/ class="iconfont icon-linkedin" title=linkedin></a><a href=https://github.com/featherbear class="iconfont icon-github" title=github></a><a href=https://www.instagram.com/_andrewjwong/ class="iconfont icon-instagram" title=instagram></a><a href=../../index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2020
<span class=heart><i class="iconfont icon-heart"></i></span><span class=author>Andrew Wong (z5206677)</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script><script type=text/javascript src=../../js/main.min.d7b7ada643c9c1a983026e177f141f7363b4640d619caf01d8831a6718cd44ea.js></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-107434487-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script src=../../js/typed.js@2.0.9></script><script src=../../js/typedjs.shortcode.js></script></body></html>